# Perceptron

The perceptron learning model is one of two algorithmically described machine learning algorithms called single layer neural networks. It is based on the McColloch-Pitts neuron, which describes
nerve cells as "simple logic [gates] with binary outputs", though the perceptron model automatically learns the optimal weight coefficients for the input
signals which determine whether an ouput signal is fired or not. This aim of this project is to create a Perceptron model, which accurately sorts data from
the Iris Dataset into two classes: Setosa and Versicolor based on the Sepal and Petal length. Though the Iris Dataset collects the widths for each Sepal and Petal
and can three types of Iris, including Viriginica, this model was created to demonstrate the basic principles of binary classification, a core part of the
Perceptron's dna. Perceptrons can extend to multi-class classification using different techniques, one example being OVA (One-vs.-All)

# ADALINE
The ADAptive LInear NEuron aws publbished by Bernard Widrow and his doctoral student Tedd Hoff a few years after Rosenblatt's perceptron model was published. The main difference between the Adaline rule and the Perceptron rule is that the weights are updated based on a linear activation function rather than a unit step function like in the perecptron. 